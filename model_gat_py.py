# -*- coding: utf-8 -*-
"""Model_GAT.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kemk-AxoflWgJ8I6sPA9bE-7BzmFtqPt
"""

model MGT(
  (temporal_embedding): TemporalEmbedding(
    (embedding_modules): ModuleList(
      (0): Embedding(73, 16)
      (1): Embedding(2, 16)
    )
    (linear): Linear(in_features=48, out_features=16, bias=True)
  )
  (spatial_embedding): SpatialEmbedding(
    (linear): Linear(in_features=8, out_features=16, bias=True)
  )
  (spatial_temporal_embedding): SpatialTemporalEmbedding(
    (linear): Linear(in_features=32, out_features=16, bias=True)
  )
  (encoder): Encoder(
    (linear): Linear(in_features=2, out_features=16, bias=True)
    (layer_stack): ModuleList(
      (0-5): 6 x EncoderLayer(
        (temporal_self_attention): TemporalSelfAttention(
          (meta_learner): MetaLearner(
            (linear1): Linear(in_features=16, out_features=16, bias=True)
            (relu): ReLU()
            (linear2): Linear(in_features=16, out_features=768, bias=True)
          )
          (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (linear): Linear(in_features=16, out_features=16, bias=False)
        )
        (spatial_self_attention): SpatialSelfAttention(
          (meta_learners): ModuleList(
            (0-2): 3 x MetaLearner(
              (linear1): Linear(in_features=16, out_features=16, bias=True)
              (relu): ReLU()
              (linear2): Linear(in_features=16, out_features=768, bias=True)
            )
          )
          (linear): Linear(in_features=48, out_features=16, bias=False)
          (dropout): Dropout(p=0.3, inplace=False)
          (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
        )
        (feed_forward): FeedForward(
          (linear1): Linear(in_features=16, out_features=16, bias=True)
          (relu): ReLU()
          (linear2): Linear(in_features=16, out_features=16, bias=True)
          (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (decoder): Decoder(
    (meta_learner): MetaLearner(
      (linear1): Linear(in_features=16, out_features=16, bias=True)
      (relu): ReLU()
      (linear2): Linear(in_features=16, out_features=512, bias=True)
    )
    (linear): Linear(in_features=2, out_features=16, bias=True)
    (layer_stack): ModuleList(
      (0-5): 6 x DecoderLayer(
        (temporal_self_attention): TemporalSelfAttention(
          (meta_learner): MetaLearner(
            (linear1): Linear(in_features=16, out_features=16, bias=True)
            (relu): ReLU()
            (linear2): Linear(in_features=16, out_features=768, bias=True)
          )
          (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (linear): Linear(in_features=16, out_features=16, bias=False)
        )
        (spatial_self_attention): SpatialSelfAttention(
          (meta_learners): ModuleList(
            (0-2): 3 x MetaLearner(
              (linear1): Linear(in_features=16, out_features=16, bias=True)
              (relu): ReLU()
              (linear2): Linear(in_features=16, out_features=768, bias=True)
            )
          )
          (linear): Linear(in_features=48, out_features=16, bias=False)
          (dropout): Dropout(p=0.3, inplace=False)
          (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
        )
        (temporal_encoder_decoder_attention): TemporalEncoderDecoderAttention(
          (meta_learner): MetaLearner(
            (linear1): Linear(in_features=16, out_features=16, bias=True)
            (relu): ReLU()
            (linear2): Linear(in_features=16, out_features=256, bias=True)
          )
          (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (linear): Linear(in_features=16, out_features=16, bias=False)
        )
        (feed_forward): FeedForward(
          (linear1): Linear(in_features=16, out_features=16, bias=True)
          (relu): ReLU()
          (linear2): Linear(in_features=16, out_features=16, bias=True)
          (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (project): Project(
      (linear): Linear(in_features=16, out_features=2, bias=True)
    )
  )
)